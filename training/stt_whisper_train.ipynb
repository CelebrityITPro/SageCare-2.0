{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12166578,"sourceType":"datasetVersion","datasetId":7662794}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Speech-to-Text with Whisper Transfer Learning\n\n**Objective:** Fine-tune a Whisper base model on the United-Syn-Med dataset to improve medical speech transcription accuracy in a live teleconsultation context.","metadata":{}},{"cell_type":"code","source":"# Installing required packages\n\n!pip install git+https://github.com/openai/whisper.git\n!pip install jiwer datasets torchaudio transformers accelerate soundfile","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T00:25:59.253138Z","iopub.execute_input":"2025-06-15T00:25:59.253889Z","iopub.status.idle":"2025-06-15T00:27:29.942080Z","shell.execute_reply.started":"2025-06-15T00:25:59.253861Z","shell.execute_reply":"2025-06-15T00:27:29.941348Z"}},"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/openai/whisper.git\n  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-ufl4m25o\n  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-ufl4m25o\n  Resolved https://github.com/openai/whisper.git to commit dd985ac4b90cafeef8712f2998d62c59c3e62d22\n  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (10.6.0)\nRequirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (0.60.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (1.26.4)\nRequirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (0.9.0)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (2.6.0+cu124)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (4.67.1)\nRequirement already satisfied: triton>=2 in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (3.2.0)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper==20240930) (0.43.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->openai-whisper==20240930) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->openai-whisper==20240930) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->openai-whisper==20240930) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->openai-whisper==20240930) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->openai-whisper==20240930) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->openai-whisper==20240930) (2.4.1)\nRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper==20240930) (2024.11.6)\nRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper==20240930) (2.32.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (4.13.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch->openai-whisper==20240930)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch->openai-whisper==20240930)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch->openai-whisper==20240930)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch->openai-whisper==20240930)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch->openai-whisper==20240930)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch->openai-whisper==20240930)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch->openai-whisper==20240930)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->openai-whisper==20240930) (1.3.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2025.4.26)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper==20240930) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->openai-whisper==20240930) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->openai-whisper==20240930) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->openai-whisper==20240930) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->openai-whisper==20240930) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->openai-whisper==20240930) (2024.2.0)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0mm00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: openai-whisper\n  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803707 sha256=ea14bf7b835e5c8fcdf80131dd4d493c4214e7fa66710b83144f5e0f6d2acdaf\n  Stored in directory: /tmp/pip-ephem-wheel-cache-hzyyn2ft/wheels/1f/1d/98/9583695e6695a6ac0ad42d87511097dce5ba486647dbfecb0e\nSuccessfully built openai-whisper\nInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, openai-whisper\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\n    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.10.19\n    Uninstalling nvidia-curand-cu12-10.3.10.19:\n      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.4.0.6\n    Uninstalling nvidia-cufft-cu12-11.4.0.6:\n      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.9.0.13\n    Uninstalling nvidia-cublas-cu12-12.9.0.13:\n      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\n    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\n    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\nSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 openai-whisper-20240930\nCollecting jiwer\n  Downloading jiwer-3.1.0-py3-none-any.whl.metadata (2.6 kB)\nRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\nRequirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.5.2)\nRequirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (0.13.1)\nRequirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from jiwer) (8.1.8)\nCollecting rapidfuzz>=3.9.7 (from jiwer)\n  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\nCollecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.31.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\nRequirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.11/dist-packages (from torchaudio) (2.6.0+cu124)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (4.13.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0->torchaudio) (1.3.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (7.0.0)\nRequirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile) (1.17.1)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile) (2.22)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.18)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.4.26)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0->torchaudio) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->datasets) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->datasets) (2024.2.0)\nDownloading jiwer-3.1.0-py3-none-any.whl (22 kB)\nDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: rapidfuzz, fsspec, jiwer\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.3.2\n    Uninstalling fsspec-2025.3.2:\n      Successfully uninstalled fsspec-2025.3.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed fsspec-2025.3.0 jiwer-3.1.0 rapidfuzz-3.13.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# import dependent libraries\n\nimport os\nimport torch\nimport whisper\nimport pandas as pd\nimport soundfile as sf\nfrom datasets import Dataset, DatasetDict\nfrom jiwer import wer, cer\nfrom transformers import WhisperProcessor, WhisperForConditionalGeneration, TrainingArguments, Trainer\nfrom dataclasses import dataclass\nfrom typing import Any, Dict, List, Union\nimport torchaudio\nfrom glob import glob\nfrom tqdm import tqdm  # for progress bar","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T00:27:29.944003Z","iopub.execute_input":"2025-06-15T00:27:29.944262Z","iopub.status.idle":"2025-06-15T00:28:03.299687Z","shell.execute_reply.started":"2025-06-15T00:27:29.944238Z","shell.execute_reply":"2025-06-15T00:28:03.298600Z"}},"outputs":[{"name":"stderr","text":"2025-06-15 00:27:48.928647: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1749947269.110560      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1749947269.163075      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Loading the data\nn = 0\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        if n < 3:\n            print(os.path.join(dirname, filename))\n            n += 1\n        else: break\n    if n >= 3: break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T00:28:03.300626Z","iopub.execute_input":"2025-06-15T00:28:03.301348Z","iopub.status.idle":"2025-06-15T00:28:03.324444Z","shell.execute_reply.started":"2025-06-15T00:28:03.301321Z","shell.execute_reply":"2025-06-15T00:28:03.323244Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/unitedsnymedsmall/unitedsynmed_small/transcript/validation.csv\n/kaggle/input/unitedsnymedsmall/unitedsynmed_small/transcript/train.csv\n/kaggle/input/unitedsnymedsmall/unitedsynmed_small/transcript/test.csv\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Paths to the dataset\naudio_root = \"/kaggle/input/unitedsnymedsmall/unitedsynmed_small/audio\"\ntranscript_root = \"/kaggle/input/unitedsnymedsmall/unitedsynmed_small/transcript/\"\n\n# Load CSVs and match them with audio paths\ndef load_split(split):\n    csv_path = os.path.join(transcript_root, f\"{split}.csv\")\n    df = pd.read_csv(csv_path)\n    df[\"path\"] = df[\"file_name\"].apply(lambda x: os.path.join(audio_root, split, x))\n    return df\n\n# Create datasets\ntrain_df = load_split(\"train\")\ntest_df = load_split(\"test\")\nval_df = load_split(\"validation\")\n\n# Convert to Hugging Face Dataset\ndataset = DatasetDict({\n    \"train\": Dataset.from_pandas(train_df),\n    \"test\": Dataset.from_pandas(test_df),\n    \"validation\": Dataset.from_pandas(val_df)\n})\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T00:28:03.327151Z","iopub.execute_input":"2025-06-15T00:28:03.327689Z","iopub.status.idle":"2025-06-15T00:28:03.557658Z","shell.execute_reply.started":"2025-06-15T00:28:03.327664Z","shell.execute_reply":"2025-06-15T00:28:03.557037Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"dataset[\"train\"][:5]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T00:28:03.558404Z","iopub.execute_input":"2025-06-15T00:28:03.558667Z","iopub.status.idle":"2025-06-15T00:28:03.567730Z","shell.execute_reply.started":"2025-06-15T00:28:03.558641Z","shell.execute_reply":"2025-06-15T00:28:03.567014Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"{'file_name': ['drug-male-0b01f9d4-980d-451f-a8f1-18e899158859.wav',\n  'drug-male-d58aac86-05d3-40ea-a61d-e1cbb7f3e790.wav',\n  'drug-female-06c23421-e597-4cf4-a912-1d44c187a4f3.wav',\n  'drug-male-9300288f-77c3-4c42-a0f6-166877f7f965.wav',\n  'drug-female-86945722-12e1-4983-bf51-6aa27b196dc9.wav'],\n 'transcription': ['Iron calx is a commonly used medicine to treat iron deficiency anemia.',\n  'If you experience nausea or vomiting, DOMPAR may help alleviate your symptoms.',\n  'AGROBEN-I is a reliable medicine for treating infections in plants.',\n  \"Make sure to follow your healthcare provider's instructions carefully while taking FEVIBID for optimal results.\",\n  'Clinical trials have shown favorable results with maralixibat chloride in pediatric patients.'],\n 'path': ['/kaggle/input/unitedsnymedsmall/unitedsynmed_small/audio/train/drug-male-0b01f9d4-980d-451f-a8f1-18e899158859.wav',\n  '/kaggle/input/unitedsnymedsmall/unitedsynmed_small/audio/train/drug-male-d58aac86-05d3-40ea-a61d-e1cbb7f3e790.wav',\n  '/kaggle/input/unitedsnymedsmall/unitedsynmed_small/audio/train/drug-female-06c23421-e597-4cf4-a912-1d44c187a4f3.wav',\n  '/kaggle/input/unitedsnymedsmall/unitedsynmed_small/audio/train/drug-male-9300288f-77c3-4c42-a0f6-166877f7f965.wav',\n  '/kaggle/input/unitedsnymedsmall/unitedsynmed_small/audio/train/drug-female-86945722-12e1-4983-bf51-6aa27b196dc9.wav']}"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# Check if GPU is available and set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T00:28:03.568483Z","iopub.execute_input":"2025-06-15T00:28:03.568750Z","iopub.status.idle":"2025-06-15T00:28:03.577103Z","shell.execute_reply.started":"2025-06-15T00:28:03.568726Z","shell.execute_reply":"2025-06-15T00:28:03.576519Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"print(f\"Using device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T00:28:03.577974Z","iopub.execute_input":"2025-06-15T00:28:03.578240Z","iopub.status.idle":"2025-06-15T00:28:03.589532Z","shell.execute_reply.started":"2025-06-15T00:28:03.578217Z","shell.execute_reply":"2025-06-15T00:28:03.588732Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"\n# # Load Whisper processor\n# processor = WhisperProcessor.from_pretrained(\"openai/whisper-base\")\n\n# # Set target sample rate\n# target_sample_rate = 16000\n\n# def preprocess(batch):\n#     audio_input, sr = sf.read(batch[\"path\"])\n    \n#     # If the sample rate is not 16kHz, resample it\n#     # if sr != target_sample_rate:\n#     waveform = torch.tensor(audio_input, dtype=torch.float32).float().to(device) \n#     if len(waveform.shape) > 1 and waveform.shape[0] > 1:\n#         waveform = waveform.mean(dim=0)  # Convert to mono\n#     resampler = torchaudio.transforms.Resample(orig_freq=sr, new_freq=target_sample_rate).to(device)\n#     audio_input = resampler(waveform).cpu().numpy()\n    \n#     inputs = processor(audio_input, sampling_rate=target_sample_rate, return_tensors=\"pt\").to(device)\n#     batch[\"input_features\"] = inputs.input_features[0].to\n#     batch[\"labels\"] = processor.tokenizer(batch[\"transcription\"]).input_ids\n#     return batch\n\n# # Apply preprocessing\n# dataset = dataset.map(preprocess)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torchaudio\nfrom transformers import WhisperProcessor\nimport torch\n\n# Initialize processor\nprocessor = WhisperProcessor.from_pretrained(\"openai/whisper-base\")\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\ndef preprocess(batch):\n    \n    # 1. Load audio file\n    waveform, sr = torchaudio.load(batch[\"path\"])\n    waveform = waveform.to(device)  # Move to GPU here\n    \n    # 2. Verify sample rate (optional if you're certain)\n    if sr != 16000:\n        raise ValueError(f\"Invalid sample rate {sr}Hz (expected 16000Hz)\")\n    \n    # 3. Convert to mono if needed\n    if waveform.dim() > 1 and waveform.shape[0] > 1:\n        waveform = waveform.mean(dim=0, keepdim=True)\n    \n    # 4. Process audio - key fix is making sure we use the tensor, not the method\n    audio_array = waveform.squeeze().cpu().numpy()  # Explicitly move to CPU first\n    \n    # 5. Generate features\n    inputs = processor(\n        audio_array,\n        sampling_rate=16000,\n        return_tensors=\"pt\"\n    )\n    \n    # 6. Prepare output - ensure we're using the actual tensors\n    batch[\"input_features\"] = inputs.input_features[0].numpy()  # Convert to numpy array\n    batch[\"labels\"] = processor.tokenizer(batch[\"transcription\"]).input_ids\n    batch[\"input_features\"] = inputs.input_features[0].cpu().numpy()\n    \n    return batch\n        \n\n# Apply preprocessing\ndataset = dataset.map(preprocess)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T00:28:03.590352Z","iopub.execute_input":"2025-06-15T00:28:03.590830Z","iopub.status.idle":"2025-06-15T00:34:11.446502Z","shell.execute_reply.started":"2025-06-15T00:28:03.590805Z","shell.execute_reply":"2025-06-15T00:34:11.445673Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/185k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fcbd7d5bcf4e41a4a38fbf7a153ba3e5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/283k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6692690578644ba28a340960dac1dd2f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/836k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db3594b6902944e7abbd0cef48341399"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.48M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c51b8f36e0ad47a987388a8f8f42f480"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/494k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc19ac75b30349a48a4cbb5b8050fa1b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"normalizer.json:   0%|          | 0.00/52.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1964081d6d5e4d7089819938d0e91d0e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/34.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6838a29f5d244c6b8c4ebb1f8532d029"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/2.19k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a98cc2e27bd4bf4b7146de2bcdb2e67"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/9500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"497459a792264b599e82b6b97c26ca56"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1200 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50b0a7e4f1ee4929a7896ae17f35226a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1200 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6b6107c82fb4700ae3612703a09d548"}},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"#save the preprocessed dataset\n\n# Define your output directory in Kaggle's working directory\noutput_dir = \"/kaggle/working/preprocessed_dataset\"\n\n# Create directory if it doesn't exist\nos.makedirs(output_dir, exist_ok=True)\n\n# Save the dataset\ndataset.save_to_disk(output_dir)\n\nprint(f\"✅ Dataset saved to {output_dir}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T00:34:11.447503Z","iopub.execute_input":"2025-06-15T00:34:11.447755Z","iopub.status.idle":"2025-06-15T00:34:46.053037Z","shell.execute_reply.started":"2025-06-15T00:34:11.447737Z","shell.execute_reply":"2025-06-15T00:34:46.052423Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Saving the dataset (0/19 shards):   0%|          | 0/9500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0299446d1967404c99eb402727225816"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Saving the dataset (0/3 shards):   0%|          | 0/1200 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5aeaf77047fd4beab6c7e5183f6abc28"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Saving the dataset (0/3 shards):   0%|          | 0/1200 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0397b82b4a684d9db6b430b98e9b7b8b"}},"metadata":{}},{"name":"stdout","text":"✅ Dataset saved to /kaggle/working/preprocessed_dataset\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# #Reload dataset incase kernel dies\n\n# from datasets import load_from_disk\n\n# # Load the saved dataset\n# dataset = load_from_disk(\"/kaggle/working/preprocessed_dataset\")\n\n# # Verify it loaded correctly\n# print(dataset)\n# print(dataset[\"train\"][0])  # Check a sample","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"@dataclass\nclass DataCollatorSpeechSeq2SeqWithPadding:\n    processor: Any\n\n    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n        input_features = [{\"input_features\": f[\"input_features\"]} for f in features]\n        label_features = [{\"input_ids\": f[\"labels\"]} for f in features]\n\n        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n\n        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch[\"input_ids\"] == self.processor.tokenizer.pad_token_id, -100)\n        batch[\"labels\"] = labels\n\n        return batch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T00:34:46.055268Z","iopub.execute_input":"2025-06-15T00:34:46.055523Z","iopub.status.idle":"2025-06-15T00:34:46.066106Z","shell.execute_reply.started":"2025-06-15T00:34:46.055505Z","shell.execute_reply":"2025-06-15T00:34:46.065484Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-base\")\n# Freeze encoder layers\nfor param in model.model.encoder.parameters():\n    param.requires_grad = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T00:34:46.066793Z","iopub.execute_input":"2025-06-15T00:34:46.067003Z","iopub.status.idle":"2025-06-15T00:34:58.157786Z","shell.execute_reply.started":"2025-06-15T00:34:46.066988Z","shell.execute_reply":"2025-06-15T00:34:58.157013Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.98k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"281897f753904e7fbe7cafb0c5b6637d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/290M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c0ea36ade9747d6be3fba2a5d7a108f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/3.81k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1ffc6bb3ff947b9adb9b0938b10dbe3"}},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"from transformers.integrations import TensorBoardCallback\n\n# Create logging directory if it doesn't exist\nos.makedirs(\"./logs\", exist_ok=True)\n\ntraining_args = TrainingArguments(\n    output_dir=\"./whisper-medical\",\n    per_device_train_batch_size=8,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    num_train_epochs=5,\n    logging_dir=\"./logs\",\n    logging_strategy=\"steps\",       # New: Log at intervals\n    logging_steps=50,              # Log every 50 steps\n    learning_rate=1e-4,\n    warmup_steps=500,\n    fp16=True,\n    push_to_hub=False,\n    report_to=\"tensorboard\",       # New: Enable TensorBoard\n    load_best_model_at_end=True,   # New: Useful for tracking\n    metric_for_best_model=\"eval_loss\",\n)\n\ndata_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=dataset[\"train\"],\n    eval_dataset=dataset[\"test\"],\n    tokenizer=processor.feature_extractor,\n    data_collator=data_collator,\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T00:35:24.732334Z","iopub.execute_input":"2025-06-15T00:35:24.732617Z","iopub.status.idle":"2025-06-15T00:35:25.663968Z","shell.execute_reply.started":"2025-06-15T00:35:24.732599Z","shell.execute_reply":"2025-06-15T00:35:25.663410Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_35/2233242723.py:26: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"\n# training_args = TrainingArguments(\n#     output_dir=\"./whisper-medical\",\n#     per_device_train_batch_size=8,\n#     eval_strategy=\"epoch\",  # Changed from evaluation_strategy\n#     save_strategy=\"epoch\",\n#     num_train_epochs=5,\n#     logging_dir=\"./logs\",\n#     learning_rate=1e-4,\n#     warmup_steps=500,\n#     fp16=True,\n#     push_to_hub=False,\n# )\n# data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)\n\n# trainer = Trainer(\n#     model=model,\n#     args=training_args,\n#     train_dataset=dataset[\"train\"],\n#     eval_dataset=dataset[\"test\"],\n#     tokenizer=processor.feature_extractor,\n#     data_collator=data_collator,\n# )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-14T18:16:24.659558Z","iopub.execute_input":"2025-06-14T18:16:24.660034Z","iopub.status.idle":"2025-06-14T18:16:29.422692Z","shell.execute_reply.started":"2025-06-14T18:16:24.660015Z","shell.execute_reply":"2025-06-14T18:16:29.422096Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_35/2511081694.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"# Confirm GPU is being used\n\nprint(f\"GPU available: {torch.cuda.is_available()}\")\nprint(f\"Device being used: {trainer.args.device}\")  # After creating trainer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T00:35:32.345715Z","iopub.execute_input":"2025-06-15T00:35:32.346280Z","iopub.status.idle":"2025-06-15T00:35:32.350654Z","shell.execute_reply.started":"2025-06-15T00:35:32.346259Z","shell.execute_reply":"2025-06-15T00:35:32.349855Z"}},"outputs":[{"name":"stdout","text":"GPU available: True\nDevice being used: cuda:0\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# Check GPU memory usage\n\n!nvidia-smi  # Works in Kaggle notebooks","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T00:35:35.688683Z","iopub.execute_input":"2025-06-15T00:35:35.689279Z","iopub.status.idle":"2025-06-15T00:35:36.347099Z","shell.execute_reply.started":"2025-06-15T00:35:35.689253Z","shell.execute_reply":"2025-06-15T00:35:36.346359Z"}},"outputs":[{"name":"stdout","text":"Sun Jun 15 00:35:36 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   68C    P0             32W /   70W |     399MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   42C    P8              9W /   70W |       3MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# Train Model\n\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T00:35:38.535584Z","iopub.execute_input":"2025-06-15T00:35:38.536495Z","iopub.status.idle":"2025-06-15T02:47:58.880422Z","shell.execute_reply.started":"2025-06-15T00:35:38.536451Z","shell.execute_reply":"2025-06-15T02:47:58.879570Z"}},"outputs":[{"name":"stderr","text":"Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.43.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\nPassing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.43.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2970' max='2970' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2970/2970 2:12:12, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.385600</td>\n      <td>0.401000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.216000</td>\n      <td>0.358396</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.087100</td>\n      <td>0.352310</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.030000</td>\n      <td>0.356789</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.008800</td>\n      <td>0.356194</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:3339: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nThere were missing keys in the checkpoint model loaded: ['proj_out.weight'].\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=2970, training_loss=0.19543793970085555, metrics={'train_runtime': 7939.7311, 'train_samples_per_second': 5.983, 'train_steps_per_second': 0.374, 'total_flos': 3.0808498176e+18, 'train_loss': 0.19543793970085555, 'epoch': 5.0})"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"def compute_metrics(pred):\n    pred_ids = pred.predictions\n    label_ids = pred.label_ids\n\n    pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)\n    label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n    label_str = processor.tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n\n    wer_score = wer(label_str, pred_str)\n    cer_score = cer(label_str, pred_str)\n\n    return {\"wer\": wer_score, \"cer\": cer_score}\n\nresults = trainer.evaluate()\nprint(results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T05:35:07.981991Z","iopub.execute_input":"2025-06-15T05:35:07.982702Z","iopub.status.idle":"2025-06-15T05:35:08.055444Z","shell.execute_reply.started":"2025-06-15T05:35:07.982679Z","shell.execute_reply":"2025-06-15T05:35:08.054344Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/1150488362.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"wer\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mwer_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"cer\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcer_score\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"],"ename":"NameError","evalue":"name 'trainer' is not defined","output_type":"error"}],"execution_count":1},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}